import os
import re
import sys
import datetime
import subprocess
from pathlib import Path
from flask import Flask, request, render_template, send_file
from openai import AzureOpenAI
from dotenv import load_dotenv

# --- Load env vars and OpenAI client ---
load_dotenv()

client = AzureOpenAI(
    api_version="2024-12-01-preview",
    api_key=os.getenv("OPENAI_API_KEY"),
    azure_endpoint="https://esehackai2507.openai.azure.com/",
)

# --- Constants ---
SWAGGER_PATH = "swagger.json"
GENERATED_DIR = Path("__generated")
STATIC_PLOT_PATH = Path("static/plot.png")

# --- Setup ---
GENERATED_DIR.mkdir(exist_ok=True)
Path("static").mkdir(exist_ok=True)

# --- Flask app ---
app = Flask(__name__)


# --- Utils ---
def slugify(text):
    return re.sub(r"[^a-z0-9]+", "_", text.lower()).strip("_")


def timestamp():
    return datetime.datetime.now().strftime("%Y-%m-%d_%H%M%S")


def generate_filename(query):
    base = slugify(query[:50]) or "plot"
    return GENERATED_DIR / f"{base}_{timestamp()}.py"


def load_api_spec(path):
    with open(path, "r") as f:
        return f.read()


def build_prompt(query: str, swagger: str) -> str:
    return f"""
You are a backend developer assistant.

You will be given:
- A user query written in natural language.
- A Swagger spec (OpenAPI v2) for an internal API.

Your job is to write a complete Python script that:
- Loads credentials from a .env file: API_BASE_URL, API_USERNAME, API_PASSWORD
- Uses HTTPBasicAuth to access the internal API (defined by the Swagger).
- Uses matplotlib to create a plot based on the data requested.
- Saves the resulting plot to a file called 'static/plot.png'.
- Does NOT use plt.show(), only plt.savefig(...).

Extra information:
- Provide the output in pure text, without any MD formatting markers.
- We are typically interested in the 'staff' view of the data
- queries to the internal API should use the header X-PROXIED-USER set to rbc


The Swagger:
{swagger}

The user query:
{query}

Return only the complete Python program.
"""


def ask_openai(query: str) -> str:
    swagger_text = load_api_spec(SWAGGER_PATH)
    prompt = build_prompt(query, swagger_text)

    response = client.chat.completions.create(
        model="o4-mini",
        messages=[
            {"role": "system", "content": "You are a helpful developer assistant."},
            {"role": "user", "content": prompt},
        ],
    )

    return response.choices[0].message.content


def run_code(code: str, path: Path) -> str | None:
    try:
        with open(path, "w") as f:
            f.write(code)

        subprocess.run([sys.executable, str(path)], check=True)
        return None
    except subprocess.CalledProcessError as e:
        return str(e)


# --- Routes ---
@app.route("/", methods=["GET", "POST"])
def index():
    plot_ready = False
    error = None
    generated_path = None

    if request.method == "POST":
        query = request.form["query"]

        try:
            code = ask_openai(query)
            file_path = generate_filename(query)
            generated_path = file_path.name

            err = run_code(code, file_path)
            if err:
                error = f"Script execution failed: {err}"
            elif not STATIC_PLOT_PATH.exists():
                error = "Plot was not generated by the script."
            else:
                plot_ready = True

        except Exception as e:
            error = str(e)

    return render_template(
        "index.html", plot_ready=plot_ready, error=error, filename=generated_path
    )


@app.route("/plot")
def plot():
    return send_file(STATIC_PLOT_PATH, mimetype="image/png")


if __name__ == "__main__":
    app.run(debug=True)
